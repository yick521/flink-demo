package com.zhugeio.demo;

import com.zhugeio.demo.generator.EventDataGenerator;
import com.zhugeio.demo.model.RawEvent;
import com.zhugeio.demo.model.IdOutput;
import com.zhugeio.demo.operator.async.*;
import com.zhugeio.demo.operator.sync.SessionIdProcessOperator;
import com.zhugeio.demo.operator.window.IdWindowedBatchOperator;
import com.zhugeio.demo.sink.PerformanceMetricsSink;
import com.zhugeio.demo.sink.KafkaSinkWithCheckpoint;
import org.apache.flink.api.java.functions.KeySelector;
import org.apache.flink.streaming.api.datastream.*;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.Serializable;
import java.util.concurrent.TimeUnit;


/**
 * ETL IDæ¨¡å—æ€§èƒ½å¯¹æ¯”ä¸»ç¨‹åºï¼ˆå®Œæ•´ç‰ˆï¼‰
 *
 * æ–°å¢åŠŸèƒ½ï¼š
 * 1. Kafka Sinkï¼ˆæ”¯æŒCheckpointï¼‰
 * 2. Exactly-Onceè¯­ä¹‰
 * 3. å¯é€‰æ‹©æ˜¯å¦å¯ç”¨Checkpoint
 *
 * è¿è¡Œå‚æ•°ï¼š
 * --mode async                    # æµå¼å¼‚æ­¥æ¨¡å¼
 * --mode window                   # å¼€çª—æ‰¹é‡æ¨¡å¼
 * --qps 3000                      # æ¯ä¸ªå¹¶è¡Œåº¦çš„QPS
 * --parallelism 16                # å¹¶è¡Œåº¦
 * --duration 10800                # æµ‹è¯•æ—¶é•¿ï¼ˆç§’ï¼‰
 * --window 5                      # çª—å£å¤§å°ï¼ˆç§’ï¼‰
 * --capacity 100                  # AsyncIOå®¹é‡
 * --checkpoint-enabled true       # æ˜¯å¦å¯ç”¨Checkpoint
 * --checkpoint-interval 60000     # Checkpointé—´éš”ï¼ˆæ¯«ç§’ï¼‰
 * --kafka-enabled true            # æ˜¯å¦å¯ç”¨Kafkaè¾“å‡º
 * --kafka-topic id-output         # Kafka Topic
 * --kafka-brokers localhost:9092  # Kafkaåœ°å€
 * --exactly-once true             # æ˜¯å¦å¯ç”¨Exactly-Once
 */
public class PerformanceComparisonJob {

    private static final Logger LOG = LoggerFactory.getLogger(PerformanceComparisonJob.class);

    public static void main(String[] args) throws Exception {

        // ========== è§£æå‚æ•° ==========
        String mode = getParameter(args, "--mode", "async");
        int qps = Integer.parseInt(getParameter(args, "--qps", "3000"));
        int parallelism = Integer.parseInt(getParameter(args, "--parallelism", "16"));
        int windowSeconds = Integer.parseInt(getParameter(args, "--window", "5"));
        int asyncCapacity = Integer.parseInt(getParameter(args, "--capacity", "100"));
        int durationSeconds = Integer.parseInt(getParameter(args, "--duration", "10800"));

        // KVRocksé…ç½®
        String kvrocksHost = getParameter(args, "--kvrocks-host", "10.10.0.115");
        int kvrocksPort = Integer.parseInt(getParameter(args, "--kvrocks-port", "7001"));


        // Checkpointé…ç½®
        boolean checkpointEnabled = Boolean.parseBoolean(
                getParameter(args, "--checkpoint-enabled", "true"));
        long checkpointInterval = Long.parseLong(
                getParameter(args, "--checkpoint-interval", "60000"));

        // Kafkaé…ç½®
        boolean kafkaEnabled = Boolean.parseBoolean(
                getParameter(args, "--kafka-enabled", "true"));
        String kafkaTopic = getParameter(args, "--kafka-topic", "id-output");
        String kafkaBrokers = getParameter(args, "--kafka-brokers", "localhost:9092");
        boolean exactlyOnce = Boolean.parseBoolean(
                getParameter(args, "--exactly-once", "true"));

        // è®¡ç®—æ•°æ®é‡
        long maxRecordsPerSubtask = (long) qps * durationSeconds;
        long totalRecords = maxRecordsPerSubtask * parallelism;

        // ========== æ‰“å°é…ç½® ==========
        LOG.info("========== ETL IDæ¨¡å—æ€§èƒ½æµ‹è¯•ï¼ˆå®Œæ•´ç‰ˆï¼‰ ==========");
        LOG.info("æ¨¡å¼: {}", mode);
        LOG.info("QPS(æ¯å¹¶è¡Œåº¦): {}", qps);
        LOG.info("å¹¶è¡Œåº¦: {}", parallelism);
        LOG.info("æ€»QPS: {}", (qps * parallelism));
        LOG.info("æµ‹è¯•æ—¶é•¿: {} ç§’ ({})",
                durationSeconds, String.format("%.2f", durationSeconds / 3600.0));
        LOG.info("é¢„è®¡æ€»æ•°æ®é‡: {} äº¿æ¡",
                String.format("%.2f", totalRecords / 100000000.0));
        LOG.info("æ¯æ¡è®°å½•å­—æ®µæ•°: 150+");

        if ("window".equals(mode)) {
            LOG.info("çª—å£å¤§å°: {}ç§’", windowSeconds);
        } else {
            LOG.info("AsyncIOå®¹é‡: {}", asyncCapacity);
        }

        LOG.info("\n---------- Checkpointé…ç½® ----------");
        LOG.info("Checkpointå¯ç”¨: {}", checkpointEnabled);
        if (checkpointEnabled) {
            LOG.info("Checkpointé—´éš”: {} ms", checkpointInterval);
            LOG.info("Checkpointæ¨¡å¼: EXACTLY_ONCE");
        }

        LOG.info("\n---------- Kafkaé…ç½® ----------");
        LOG.info("Kafkaè¾“å‡ºå¯ç”¨: {}", kafkaEnabled);
        if (kafkaEnabled) {
            LOG.info("Kafka Topic: {}", kafkaTopic);
            LOG.info("Kafka Brokers: {}", kafkaBrokers);
            LOG.info("Exactly-Onceè¯­ä¹‰: {}", exactlyOnce);
        }
        LOG.info("===================================================\n");

        // ========== åˆ›å»ºæ‰§è¡Œç¯å¢ƒ ==========
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.disableOperatorChaining();
        env.setParallelism(parallelism);

        // ========== é…ç½®Checkpoint ==========
        if (checkpointEnabled) {
            env.enableCheckpointing(checkpointInterval);
            env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
            env.getCheckpointConfig().setMinPauseBetweenCheckpoints(checkpointInterval / 2);
            env.getCheckpointConfig().setCheckpointTimeout(600000);  // 10åˆ†é’Ÿè¶…æ—¶
            env.getCheckpointConfig().setMaxConcurrentCheckpoints(1);

            LOG.info("âœ… Checkpointå·²å¯ç”¨ï¼ˆExactly-Onceæ¨¡å¼ï¼‰\n");
        } else {
            LOG.info("âš ï¸  Checkpointæœªå¯ç”¨ï¼ˆæ— å®¹é”™ä¿è¯ï¼‰\n");
        }

        // ========== æ•°æ®æº ==========
        DataStream<RawEvent> source = env
                .addSource(new EventDataGenerator(qps, maxRecordsPerSubtask))
                .name("EventGenerator")
                .uid("event-generator")
                .setParallelism(parallelism);

        // ========== å¤„ç†é€»è¾‘ ==========
        DataStream<IdOutput> result;

        if ("async".equals(mode)) {
            result = processWithAsyncIO(source, asyncCapacity, kvrocksHost, kvrocksPort, parallelism);
        } else if ("window".equals(mode)) {
            result = processWithWindow(source, windowSeconds, kvrocksHost, kvrocksPort);
        } else {
            throw new IllegalArgumentException("Unknown mode: " + mode);
        }


        // ========== Kafka Sinkï¼ˆå¯é€‰ï¼‰ ==========
        if (kafkaEnabled) {
            KafkaSinkWithCheckpoint.addKafkaSink(
                    result,
                    kafkaTopic,
                    kafkaBrokers,
                    exactlyOnce && checkpointEnabled  // Exactly-Onceéœ€è¦Checkpoint
            );

            LOG.info("âœ… Kafka Sinkå·²æ·»åŠ ï¼ˆTopic: {}ï¼‰\n", kafkaTopic);
        }

        // ========== æ€§èƒ½æŒ‡æ ‡æ”¶é›† ==========
        result.addSink(new PerformanceMetricsSink(mode.toUpperCase()))
                .name("PerformanceMetricsSink")
                .uid("performance-metrics-sink")
                .setParallelism(1);

        // ========== æ‰§è¡Œ ==========
        String jobName = String.format("ETL-ID-%s-%s-Checkpoint%s",
                mode.toUpperCase(),
                String.format("%.1fM", totalRecords / 1000000.0),
                checkpointEnabled ? "-ON" : "-OFF"
        );

        LOG.info("ğŸš€ å¼€å§‹æ‰§è¡Œï¼š{}\n", jobName);

        env.execute(jobName);
    }

    private static DataStream<IdOutput> processWithAsyncIO(
            DataStream<RawEvent> source,
            int capacity,
            String kvrocksHost,
            int kvrocksPort, int parallelism) {

        LOG.info("ğŸ“Š ä½¿ç”¨æµå¼å¼‚æ­¥å¤„ç†ï¼ˆAsyncIO + çœŸå®KVRocksï¼‰\n");

        // 1. è®¾å¤‡IDæ˜ å°„
        SingleOutputStreamOperator<IdOutput> withDeviceId = AsyncDataStream.unorderedWait(
                        source,
                        new DeviceIdAsyncOperator(kvrocksHost, kvrocksPort, true),  // â† ä¼ å…¥KVRocksåœ°å€
                        70000, TimeUnit.MILLISECONDS, capacity
                ).name("DeviceIdAsyncIO")
                .uid("deviceidasync")
                .setParallelism(parallelism);

        // 2. ä¼šè¯IDå¤„ç†
        SingleOutputStreamOperator<IdOutput> withSessionId = AsyncDataStream.unorderedWait(
                        withDeviceId,
                        new SessionIdAsyncOperator(),  // â† ä¼ å…¥KVRocksåœ°å€
                        70000, TimeUnit.MILLISECONDS, capacity
                ).name("UserIdAsyncIO")
                .uid("sessionidasync")
                .setParallelism(parallelism);

        // 3. ç”¨æˆ·IDæ˜ å°„
        SingleOutputStreamOperator<IdOutput> withUserId = AsyncDataStream.unorderedWait(
                        withSessionId,
                        new UserIdAsyncOperator(kvrocksHost, kvrocksPort),  // â† ä¼ å…¥KVRocksåœ°å€
                        70000, TimeUnit.MILLISECONDS, capacity
                ).name("UserIdAsyncIO")
                .uid("useridasync")
                .setParallelism(parallelism);

        // 4. è¯¸è‘›IDæ˜ å°„
        SingleOutputStreamOperator<IdOutput> withZgid = AsyncDataStream.unorderedWait(
                        withUserId,
                        new ZgidAsyncOperator(kvrocksHost, kvrocksPort),  // â† ä¼ å…¥KVRocksåœ°å€
                        70000, TimeUnit.MILLISECONDS, capacity
                ).name("ZgidAsyncIO")
                .uid("zgidasync")
                .setParallelism(parallelism);

        return withZgid;
    }

    /**
     * æ–¹æ¡ˆBï¼šå¼€çª—æ‰¹é‡å¤„ç†
     */
    private static DataStream<IdOutput> processWithWindow(
            DataStream<RawEvent> source, int windowSeconds, String kvrocksHost, int kvrocksPort) {

        LOG.info("ğŸ“Š ä½¿ç”¨å¼€çª—æ‰¹é‡å¤„ç†ï¼ˆWindow + çœŸå®KVRocksï¼‰\n");
        
        int parallelism = source.getParallelism();

        DataStream<IdOutput> result = source
                .keyBy(event -> event.getDeviceId())
                .window(TumblingProcessingTimeWindows.of(Time.seconds(windowSeconds)))
                .process(new IdWindowedBatchOperator(kvrocksHost, kvrocksPort, true))  // â† ä¼ å…¥KVRocksåœ°å€
                .name("IDWindowedBatch")
                .uid("idwindowedbatch");

        return result;
    }

    private static String getParameter(String[] args, String key, String defaultValue) {
        for (int i = 0; i < args.length - 1; i++) {
            if (args[i].equals(key)) {
                return args[i + 1];
            }
        }
        return defaultValue;
    }
}